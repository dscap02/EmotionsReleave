Index: Metodi Pietro/Modeling.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from collections import defaultdict\r\n\r\nimport pandas as pd\r\n\r\nimport string\r\nimport asyncio\r\nimport deepl\r\nfrom nltk.corpus import stopwords\r\nfrom nltk.tokenize import word_tokenize\r\nfrom googletrans import Translator\r\nimport nltk\r\nfrom sklearn.model_selection import train_test_split\r\n\r\n#risorse nltk\r\nnltk.download('punkt')\r\nnltk.download('stopwords')\r\n\r\ndataset = pd.read_csv(\"../dataset_finale_bilanciato.csv\", sep='\\t', header=None)\r\n\r\ndataset = dataset.drop(index=0)\r\n\r\n\r\n\r\n\r\n# Separiamo la colonna in due per testo ed emozione\r\ndataset[['0', '1']] = dataset[0].str.split(',', expand=True, n=1)\r\n\r\n\r\ndataset['1'] = dataset['1'].astype(str)\r\n\r\n# Rimuoviamo la colonna originale che ora è separata\r\ndf_filtered = dataset.drop(columns=[0])\r\n\r\n\r\n# Funzione per preprocessare il testo e normalizzarlo\r\nstop_words = set(stopwords.words('english'))\r\n\r\ndef preprocess_text(text):\r\n    # Convertiamo in minuscolo\r\n    text = text.lower()\r\n    # Rimuoviamo la punteggiatura\r\n    text = text.translate(str.maketrans('', '', string.punctuation))\r\n    # Tokenizziamo il testo\r\n    words = word_tokenize(text)\r\n    # Rimuoviamo le stopwords\r\n    words = [word for word in words if word not in stop_words]\r\n    return \" \".join(words)\r\n\r\n\r\ndf_filtered['0']=df_filtered['0'].apply(preprocess_text)\r\n\r\n# Suddivisione in training set e test set\r\ntrain_set, test_set = train_test_split(df_filtered, test_size=0.2, random_state=42)\r\n\r\n\r\n\r\n\r\n# Calcolo delle frequenze nel training set\r\nemozione_counts = train_set['1'].value_counts().to_dict()\r\ntotale_messaggi = len(train_set)\r\n\r\n# Calcolo della frequenza delle parole per emozione\r\nparole_per_emozione = defaultdict(list)\r\nfor idx, row in train_set.iterrows():\r\n    parole = row['0'].split()  # Ottieni le parole preprocessate\r\n    parole_per_emozione[row['1']].extend(parole)\r\n\r\n# Calcolo della frequenza totale delle parole nel training set\r\nfrequenza_totale_parole = defaultdict(int)\r\nfor testo_normalizzato in train_set['0']:\r\n    for parola in testo_normalizzato.split():\r\n        frequenza_totale_parole[parola] += 1\r\n\r\n# Funzioni per calcolare le probabilità\r\ndef calcola_prob_emozione(emozione):\r\n    return emozione_counts.get(emozione, 0) / totale_messaggi\r\n\r\ndef calcola_prob_parola_emozione(parola, emozione):\r\n    parole = parole_per_emozione[emozione]\r\n    totale_parole = len(parole)\r\n    frequenza_parola = parole.count(parola)\r\n    return (frequenza_parola + 1) / (totale_parole + len(frequenza_totale_parole))\r\n\r\ndef calcola_prob_parola(parola):\r\n    \"\"\"P(parola): frequenza della parola nel dataset\"\"\"\r\n    totale_parole_dataset = sum(frequenza_totale_parole.values())\r\n    frequenza_parola = frequenza_totale_parole.get(parola, 0)\r\n    return frequenza_parola / totale_parole_dataset\r\n\r\n\r\ndef calcola_prob_emozione_messaggio(messaggio, emozione):\r\n    parole = messaggio.split()  # Il messaggio è già preprocessato\r\n    prob_parola_emozione = 1\r\n\r\n    # Moltiplichiamo la probabilità di ciascuna parola condizionata dall'emozione\r\n    for parola in parole:\r\n        prob_parola_emozione *= calcola_prob_parola_emozione(parola, emozione)\r\n\r\n    # Calcoliamo la probabilità della singola parola P(w_i) nel dataset\r\n    prob_parola_indipendente = 1\r\n    for parola in parole:\r\n        prob_parola_indipendente *= calcola_prob_parola(parola)\r\n\r\n    # Probabilità a priori dell'emozione\r\n    prob_emozione = calcola_prob_emozione(emozione)\r\n\r\n    # Calcoliamo la probabilità finale con il Teorema di Bayes, considerando la parola indipendente\r\n    prob_emozione_messaggio = prob_emozione * prob_parola_emozione * prob_parola_indipendente\r\n\r\n    return prob_emozione_messaggio\r\n\r\ndef predici_emozione(messaggio):\r\n    probabilita_emozioni = {\r\n        emozione: calcola_prob_emozione_messaggio(messaggio, emozione)\r\n        for emozione in emozione_counts.keys()\r\n    }\r\n    return max(probabilita_emozioni, key=probabilita_emozioni.get)\r\n\r\n# Funzione per caricare messaggi da un file di testo\r\ndef carica_test_da_file(file_path):\r\n    with open(file_path, 'r', encoding='utf-8') as file:\r\n        lines = file.readlines()\r\n    messaggi = [line.strip().split('\\t') for line in lines if line.strip()]\r\n    # Assumiamo che il file contenga: testo \\t emozione_reale\r\n    return [(preprocess_text(m[0]), m[1]) for m in messaggi]\r\n\r\n# Caricamento del file di test\r\ntest_file_path = \"test_messages.txt\"  # Inserisci il percorso al tuo file di test\r\ntest_messaggi = carica_test_da_file(test_file_path)\r\n\r\n# Calcolo delle predizioni e dell'accuratezza\r\nerrori = []\r\ntotale_test = len(test_messaggi)\r\ncorretti = 0\r\n\r\nfor messaggio, emozione_reale in test_messaggi:\r\n    predizione = predici_emozione(messaggio)\r\n    if predizione == emozione_reale:\r\n        corretti += 1\r\n    else:\r\n        errori.append({\r\n            \"messaggio\": messaggio,\r\n            \"emozione_reale\": emozione_reale,\r\n            \"emozione_predetta\": predizione\r\n        })\r\n\r\n# Risultati\r\naccuracy = corretti / totale_test\r\nprint(f\"Accuratezza finale: {accuracy:.4f}\")\r\n\r\n# Messaggi con predizioni errate\r\nprint(\"\\nMESSAGGI CON PREDIZIONI ERRATE:\")\r\nfor errore in errori:\r\n    print(f\"Messaggio: {errore['messaggio']}\")\r\n    print(f\"Emozione reale: {errore['emozione_reale']}\")\r\n    print(f\"Emozione predetta: {errore['emozione_predetta']}\")\r\n    print(\"-\" * 50)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n
===================================================================
diff --git a/Metodi Pietro/Modeling.py b/Metodi Pietro/Modeling.py
--- a/Metodi Pietro/Modeling.py	(revision 00b1a49428d1d3183db78db0fd04abc6e0a30f17)
+++ b/Metodi Pietro/Modeling.py	(date 1737981991305)
@@ -59,7 +59,7 @@
 emozione_counts = train_set['1'].value_counts().to_dict()
 totale_messaggi = len(train_set)
 
-# Calcolo della frequenza delle parole per emozione
+# Vocabolario contenente delle parole per emozione
 parole_per_emozione = defaultdict(list)
 for idx, row in train_set.iterrows():
     parole = row['0'].split()  # Ottieni le parole preprocessate
